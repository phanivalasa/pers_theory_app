{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to estimate y hat given coefficients beta and data X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_yhat(beta, X):\n",
    "    \"\"\" (array, array) -> array\n",
    "    Returns the estimate y hat computed using the coefficients beta and input data array X   \n",
    "    \"\"\"\n",
    "    yhat = np.matmul(beta, X.T)\n",
    "    return yhat.reshape(yhat.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to estimate RSS given coefficients beta, data containing independent vars X and dependent var y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RSS(beta, X, y):\n",
    "    \"\"\" (array, array, array) -> float\n",
    "    Returns the Sum of Squared errors calculated using the coefficients beta, input data array X and the corresponding actual value of y    \n",
    "    \"\"\"\n",
    "    yhat = estimate_yhat(beta, X)    \n",
    "    return np.sum((y - yhat) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "winedata = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = winedata[winedata.columns[:-1]]\n",
    "y = winedata[['quality']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling 80% of data randomly for training and keeping the remainder for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X.sample(frac=0.8)\n",
    "y_train = y.iloc[X_train.index]\n",
    "X_test = X.iloc[list(set(X.index) - set(X_train.index))]\n",
    "y_test = y.iloc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize beta0 to random values from the standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta0 = np.random.normal(0, 1, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal values of beta using the minimize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = minimize(fun=RSS, x0=beta0, args=(X_train,y_train))\n",
    "beta_hat = res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting y for both training and test using the optimized values beta hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = estimate_yhat(beta_hat, X_train)\n",
    "y_test_pred = estimate_yhat(beta_hat, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing RSS for both training and test using the optimized values beta hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RSS_train = RSS(beta_hat, X_train, y_train)\n",
    "RSS_test = RSS(beta_hat, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing RSS values and beta hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RSS value for the training data set is 513.72\n"
     ]
    }
   ],
   "source": [
    "print (\"The RSS value for the training data set is {0:.2f}\".format(RSS_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RSS value for the test data set is 154.97\n"
     ]
    }
   ],
   "source": [
    "print (\"The RSS value for the test data set is {0:.2f}\".format(RSS_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity : -0.0023\n",
      "volatile acidity : -1.1731\n",
      "citric acid : -0.2621\n",
      "residual sugar : 0.0282\n",
      "chlorides : -2.1116\n",
      "free sulfur dioxide : 0.0044\n",
      "total sulfur dioxide : -0.0036\n",
      "density : 4.8477\n",
      "pH : -0.5639\n",
      "sulphates : 0.8828\n",
      "alcohol : 0.2891\n"
     ]
    }
   ],
   "source": [
    "for val in range(len(winedata.columns)-1):\n",
    "    print (winedata.columns[val],':',\"{0:.4f}\".format(round(beta_hat[val],4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>__1. What are the qualitative results from your model? Which features seem to be most\n",
    "important? Do you think that the magnitude of the features in X may affect the\n",
    "results (for example, the average total sulfur dioxide across all wines is 46.47, but\n",
    "the average chlorides is only 0.087).__\n",
    "\n",
    "- _Going by the coefficients beta for each variable, it seems that the density is the most important feature as it has the highest absolute value for beta. However, the magnitudes of the features are very different. Density has an average value of 0.996 which is very small compared to features like alcohol with a mean value of 10. The magnitude of these features have an impact on the magnitude of the coefficients and hence the coefficients cannot be directly compared to understand feature importance. For example, keeping all else constant, if density was multiplied by 10 and used in the regression, its coefficient would have been 10 times smaller (the units make a difference). Hence, when the magnitudes of the features are very different, some preprocessing like scaling/standardizing maybe required before coefficient comparison._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>__2. How well does your model fit? You should be able to measure the goodness of fit,\n",
    "RSS, on both the training data and the test data, but only report the results on the\n",
    "test data. In Machine Learning we almost always only care about how well the\n",
    "model fits on data that has not been used to fit the model, because we need to use\n",
    "the model in the future, not the past. Therefore, we only report performance with\n",
    "holdout data, or test data.__\n",
    "- _The RSS on the test data is 154.97. The RSS is a function of number of data points in the dataset, so it can mainly be used for comparison across different methods_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get the RSS given the arguments of the minimize function and the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RSS_minimize(beta0, X_test, y_test, solver='BFGS'):\n",
    "    res = minimize(fun=RSS, x0=beta0, method=solver, args=(X_train,y_train))\n",
    "    beta_hat = res.x\n",
    "    return RSS(beta_hat, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating and printing the RSS for different starting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RSS_1 = RSS_minimize(beta0=[1,20,-3,24,-95,1116,-7000,88,91,190,-311], X_test=X_test, y_test=y_test)\n",
    "RSS_2 = RSS_minimize(beta0=list(range(10000,10011)), X_test=X_test, y_test=y_test)\n",
    "RSS_3 = RSS_minimize(beta0=list(range(-20,-31,-1)), X_test=X_test, y_test=y_test)\n",
    "RSS_4 = RSS_minimize(beta0=list(range(-20000,-20011,-1)), X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of RSS for different starting points are 154.97, 154.97, 154.97, 154.97\n"
     ]
    }
   ],
   "source": [
    "print('The values of RSS for different starting points are {0:.2f}, {0:.2f}, {0:.2f}, {0:.2f}'.format(RSS_1, RSS_2, RSS_3, RSS_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 26.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "RSS_1 = RSS_minimize(beta0=[1,20,-3,24,-95,1116,-7000,88,91,190,-311], X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 30.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "RSS_2 = RSS_minimize(beta0=list(range(10000,10011)), X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 18.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "RSS_3 = RSS_minimize(beta0=list(range(-20,-31,-1)), X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 31.2 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "RSS_4 = RSS_minimize(beta0=list(range(-20000,-20011,-1)), X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>__3. Does the end result or RSS change if you try different initial values of β? What\n",
    "happens if you change the magnitude of the initial β?__\n",
    "- _For the different initial values used above, the end result and the RSS does not change. However, the execution time changes. Based on observation of the limited trials, it looks like the execution is faster if our initial values are relatively closer to the optimized beta values._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out different solver methods for the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta0 = np.random.normal(0, 1, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver_methods = ['Nelder-Mead', 'Powell', 'CG', 'BFGS', 'L-BFGS-B', 'TNC', 'COBYLA', 'SLSQP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS for different solver methods:\n",
      "Nelder-Mead: 936.88\n",
      "Powell: 154.98\n",
      "CG: 155.05\n",
      "BFGS: 154.97\n",
      "L-BFGS-B: 154.99\n",
      "TNC: 222.66\n",
      "COBYLA: 340.31\n",
      "SLSQP: 154.97\n"
     ]
    }
   ],
   "source": [
    "solver_RSS = OrderedDict()\n",
    "for solver_method in solver_methods:\n",
    "    solver_RSS[solver_method] = RSS_minimize(beta0=beta0, X_test = X_test, y_test = y_test, solver=solver_method)\n",
    "\n",
    "solver_RSS_print = [str(x)+\": \"+str(round(solver_RSS[x],2)) for x in solver_RSS]\n",
    "\n",
    "print ('RSS for different solver methods:')\n",
    "for val in solver_RSS_print:\n",
    "    print (val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>__4. Does the choice of solver method change the end result or RSS?__\n",
    "- _Based on the test performed, the choice of solver method does change the end result as the RSS changes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to estimate RSS given coefficients beta, data containing independent vars X and dependent var y and regularization parameter lambda_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RSS_regularized(beta, X, y, lambda_reg, reg_type = 'l2'):\n",
    "    \"\"\" (array, array, array) -> float\n",
    "    Returns the Sum of Squared errors calculated using the coefficients beta, input data array X and the corresponding actual value of y    \n",
    "    \"\"\"\n",
    "    yhat = estimate_yhat(beta, X)    \n",
    "      \n",
    "    if reg_type == 'l2':\n",
    "        return np.sum((y - yhat) ** 2) + (lambda_reg * np.sum(beta**2))\n",
    "    elif reg_type == 'l1':\n",
    "        return np.sum((y - yhat) ** 2) + (lambda_reg * np.sum(np.abs(beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RSS_minimize_reg(beta0, X_test, y_test, lambda_reg=0.01, reg_type='l2'):\n",
    "    res = minimize(fun=RSS_regularized, x0=beta0, args=(X_train, y_train, lambda_reg, reg_type))\n",
    "    beta_hat = res.x\n",
    "    return RSS(beta_hat, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_reg_RSS_train = OrderedDict()\n",
    "for lambda_reg in [0, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50]:\n",
    "    l2_reg_RSS_train[lambda_reg] = RSS_minimize_reg(beta0=beta0, X_test = X_train, y_test = y_train, lambda_reg=lambda_reg, reg_type='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training dataset for different lambda values:\n",
      "0: 513.717\n",
      "0.01: 513.721\n",
      "0.05: 513.797\n",
      "0.1: 514.002\n",
      "0.5: 517.052\n",
      "1: 520.614\n",
      "5: 531.618\n",
      "10: 537.36\n",
      "50: 562.325\n"
     ]
    }
   ],
   "source": [
    "l2_reg_RSS_train_print = [str(x)+\": \"+str(round(l2_reg_RSS_train[x],3)) for x in l2_reg_RSS_train]\n",
    "\n",
    "print ('RSS on training dataset for different lambda values:')\n",
    "for val in l2_reg_RSS_train_print:\n",
    "    print (val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_reg_RSS_test = OrderedDict()\n",
    "for lambda_reg in [0, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50]:\n",
    "    l2_reg_RSS_test[lambda_reg] = RSS_minimize_reg(beta0=beta0, X_test = X_test, y_test = y_test, lambda_reg=lambda_reg, reg_type='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training dataset for different lambda values:\n",
      "0: 154.972\n",
      "0.01: 154.922\n",
      "0.05: 154.752\n",
      "0.1: 154.593\n",
      "0.5: 154.282\n",
      "1: 154.485\n",
      "5: 155.452\n",
      "10: 156.023\n",
      "50: 160.531\n"
     ]
    }
   ],
   "source": [
    "l2_reg_RSS_test_print = [str(x)+\": \"+str(round(l2_reg_RSS_test[x],3)) for x in l2_reg_RSS_test]\n",
    "\n",
    "print ('RSS on training dataset for different lambda values:')\n",
    "for val in l2_reg_RSS_test_print:\n",
    "    print (val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>__Try adding in an L2 (aka Ridge) regularization penalty to your model above to create a new,\n",
    "regularized model. See equation 3.41 for guidance. You will need to choose a value of\n",
    "lambda, so start with something small, like 0.01. \n",
    "<br><br> 1. How does RSS on the training data change? How does RSS on the test data change?__\n",
    "\n",
    "- _On adding an L2 penalty of 0.01, the training RSS increased marginally while the test RSS decreased marginally. _\n",
    "\n",
    "<br> __2. What happens if you try different values of lambda? Can you roughly tune lambda to get\n",
    "the best results on the test data?__\n",
    "\n",
    "- _On testing different values of lambda and looking at performance on the test set (using RSS) , we can use a lambda value of 0.5 that seems to provide a relatively lower RSS(compared to other values of lambda). Also, as lambda increases, the test RSS first decreases and then continues to increase indicating that there may be an optimum point_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_reg_RSS_train = OrderedDict()\n",
    "for lambda_reg in [0, 0.01, 0.05, 0.1, 0.5, 1, 2.5, 5, 7.5, 10, 50]:\n",
    "    l1_reg_RSS_train[lambda_reg] = RSS_minimize_reg(beta0=beta0, X_test = X_train, y_test = y_train, lambda_reg=lambda_reg, reg_type='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training dataset for different lambda values:\n",
      "0: 513.717\n",
      "0.01: 513.717\n",
      "0.05: 513.719\n",
      "0.1: 513.725\n",
      "0.5: 513.898\n",
      "1: 514.441\n",
      "2.5: 518.244\n",
      "5: 523.764\n",
      "7.5: 533.65\n",
      "10: 541.195\n",
      "50: 578.534\n"
     ]
    }
   ],
   "source": [
    "l1_reg_RSS_train_print = [str(x)+\": \"+str(round(l1_reg_RSS_train[x],3)) for x in l1_reg_RSS_train]\n",
    "\n",
    "print ('RSS on training dataset for different lambda values:')\n",
    "for val in l1_reg_RSS_train_print:\n",
    "    print (val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_reg_RSS_test = OrderedDict()\n",
    "for lambda_reg in [0, 0.01, 0.05, 0.1, 0.5, 1, 2.5, 5, 7.5, 10, 50]:\n",
    "    l1_reg_RSS_test[lambda_reg] = RSS_minimize_reg(beta0=beta0, X_test = X_test, y_test = y_test, lambda_reg=lambda_reg, reg_type='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training dataset for different lambda values:\n",
      "0: 154.972\n",
      "0.01: 154.963\n",
      "0.05: 154.928\n",
      "0.1: 154.886\n",
      "0.5: 154.591\n",
      "1: 154.312\n",
      "2.5: 154.089\n",
      "5: 153.938\n",
      "7.5: 155.089\n",
      "10: 156.368\n",
      "50: 163.498\n"
     ]
    }
   ],
   "source": [
    "l1_reg_RSS_test_print = [str(x)+\": \"+str(round(l1_reg_RSS_test[x],3)) for x in l1_reg_RSS_test]\n",
    "\n",
    "print ('RSS on training dataset for different lambda values:')\n",
    "for val in l1_reg_RSS_test_print:\n",
    "    print (val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__3. Now try using an L1 (aka Lasso) regularization penalty instead. See equation 3.51 for\n",
    "example. Report your findings on how RSS changes, and if you can roughly tune lambda__\n",
    "\n",
    "- _On testing different values of lambda and looking at performance on the test set (using RSS) , we can use a lambda value of 5 that seems to provide a relatively lower RSS (compared to other values of lambda). Also, as lambda increases, the test RSS first decreases and then continues to increase indicating that there may be an optimum point_\n",
    "\n",
    "\n",
    "__4. Again, do you think that the magnitude of the features in X may affect the results with\n",
    "regularization?__\n",
    "\n",
    "- _By observation of the regularization objective, it seems that regularization focuses on shrinking the beta coefficient associated with each variable. But generally, the size of the beta coefficients is also a function of the magnitude of the features (with all else same, as units of one feature are changed, the betas get scaled accordingly). In other words, the size of the betas determine how cheap/expensive it is to include the feature as the betas contribute to the function we try to minimize. Hence, we need some form of scaling/standardization before we run regularized regression in order to treat the features fairly._\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
